{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "import audiosegment\n",
    "from multiprocessing import Pool\n",
    "modulePath = '../../lib/ChristiansPythonLibrary/src' \n",
    "import sys\n",
    "import numpy\n",
    "sys.path.append(modulePath)\n",
    "import generalUtility\n",
    "import dspUtil\n",
    "import matplotlibUtil\n",
    "import librosa\n",
    "import pickle\n",
    "import acousticFeatures\n",
    "\n",
    "\n",
    "#Constant\n",
    "EMOTION_ANNOTATORS = {'anger': 0, 'happiness' : 1, 'sadness' : 2, 'neutral' : 3, 'frustration' : 4, 'excited': 5,\n",
    "           'fear' : 6,'surprise' : 7,'disgust' : 8, 'other' : 9}\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n",
    "METHOD = {'audio_feature':0, 'LSTM':1}\n",
    "\n",
    "#Method for classification\n",
    "method = METHOD['audio_feature']\n",
    "\n",
    "\n",
    "isRawDataProcessed = False\n",
    "\n",
    "#Development mode. Only run with small data.\n",
    "dev = False\n",
    "\n",
    "onlyAcoustic = True\n",
    "\n",
    "\n",
    "#Define class\n",
    "class Input:\n",
    "    ##spectral, prosody, erergy are dict type\n",
    "    def __init__(self, spectral, prosody, energy, spectrogram, onlyAcoustic = False, acoustic_features):\n",
    "        self.spectral = spectral\n",
    "        self.prosody = prosody\n",
    "        self.energy = energy\n",
    "        self.spectrogram = spectrogram\n",
    "        self.onlyAcoustic = onlyAcoustic\n",
    "        self.acoustic_features = acoustic_features\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"spectral  features: \", spectral)\n",
    "        print(\"prosody features: \", prosody)\n",
    "        print(\"energy: \", energy)\n",
    "        print(\"spectrogram: \", spectrogram)\n",
    "        \n",
    "    def input2Vec(self, onlySpectrogram):\n",
    "        if (onlySpectrogram ==  False):\n",
    "            features = []\n",
    "            if (onlyAcoustic == False):\n",
    "                s = list(self.spectral.values())\n",
    "                p = list(self.prosody.values())\n",
    "                e = list(self.energy.values())\n",
    "                [features.extend(x) for x in [s, p, e]]\n",
    "            else:\n",
    "                features = acoustic_features\n",
    "            return features\n",
    "        else :\n",
    "            return self.spectrogram\n",
    "    \n",
    "class Output:\n",
    "    def __init__(self, duration, code, category_origin, category_evaluation, attribute):\n",
    "        self.duration = duration\n",
    "        self.code = code\n",
    "        self.category_origin = category_origin\n",
    "        self.category_evaluation = category_evaluation\n",
    "        self.attribute = attribute\n",
    "        \n",
    "     \n",
    "    def print(self):\n",
    "        print(\"duration: \", self.duration)\n",
    "        print(\"code: \", self.code)\n",
    "        print(\"category_origin: \", self.category_origin)\n",
    "        print(\"category_evaluation: \", self.category_evaluation)\n",
    "        print(\"attribute: \", self.attribute)\n",
    "        \n",
    "    def output2Vec(self):\n",
    "        emotion = EMOTION[self.category_origin]\n",
    "        return emotion\n",
    "    \n",
    "    \n",
    "    \n",
    "#Functions for get features from audio file\n",
    "def amp2Db(samples):\n",
    "    dbs = []\n",
    "    for  x in samples:\n",
    "        if x < 0:\n",
    "            v = - dspUtil.rmsToDb(np.abs(x))\n",
    "        elif x == 0:\n",
    "            v = 0\n",
    "        else :\n",
    "            v = dspUtil.rmsToDb(np.abs(x))\n",
    "        dbs.append(v)\n",
    "    return dbs\n",
    "\n",
    "def getF0Features(file):\n",
    "    features = {}\n",
    "    sound = audiosegment.from_file(file)\n",
    "    voiced = sound.filter_silence(duration_s=0.2)\n",
    "    frame_rate = sound.frame_rate\n",
    "    frames = sound.dice(0.032)\n",
    "\n",
    "    f0s = []\n",
    "    for f in frames:\n",
    "        f0 = dspUtil.calculateF0once(amp2Db(f.get_array_of_samples()), frame_rate)\n",
    "        if(f0 != 0):\n",
    "            f0s.append(f0)\n",
    "    \n",
    "    features['f0_min'] = np.min(f0s)\n",
    "    features['f0_max'] = np.max(f0s)\n",
    "    features['f0_range'] = np.max(f0s) - np.min(f0s)\n",
    "    features['f0_mean'] = np.mean(f0s)\n",
    "    features['f0_median'] = np.median(f0s)\n",
    "    features['f0_25th'] = np.percentile(f0s, 25)\n",
    "    features['f0_75th'] = np.percentile(f0s, 75)\n",
    "    features['f0_std'] = np.std(f0s)\n",
    "    \n",
    "  \n",
    "    return features\n",
    "\n",
    "def getEnergyFeatures(file):\n",
    "    features = {}\n",
    "    sound = audiosegment.from_file(file)\n",
    "    voiced = sound.filter_silence(duration_s=0.2)\n",
    "    samples = voiced.get_array_of_samples()\n",
    "    frame_rate = sound.frame_rate\n",
    "    frames = sound.dice(0.032)\n",
    "    \n",
    "    e = []\n",
    "    for f in frames:\n",
    "        e.append(np.abs(f.max_dBFS))\n",
    "    \n",
    "    \n",
    "    features['energy_min'] = np.min(e)\n",
    "    features['energy_max'] = np.max(e)\n",
    "    features['energy_range'] = np.max(e) - np.min(e)\n",
    "    features['energy_mean'] = np.mean(e)\n",
    "    features['energy_median'] = np.median(e)\n",
    "    features['energy_25th'] = np.percentile(e, 25)\n",
    "    features['energy_75th'] = np.percentile(e, 75)\n",
    "    features['energy_std'] = np.std(e)   \n",
    "\n",
    "    return features\n",
    "    \n",
    "def audio2Features(file):\n",
    "    spectral = {}\n",
    "    prosody = {}\n",
    "    energy = {}\n",
    "    try:\n",
    "        if (onlyAcoustic == False):\n",
    "            prosody = getF0Features(file)\n",
    "            energy = getEnergyFeatures(file)\n",
    "            y, sr = librosa.load(file)\n",
    "            spectrogram = librosa.stft(y)\n",
    "            spectrogram = np.abs(spectrogram)\n",
    "            #To be continued....\n",
    "            return Input(spectral, prosody, energy, spectrogram)\n",
    "        else :\n",
    "            acoustic_features = acousticFeatures.getAllFeatures(file)\n",
    "            return Input(onlyAcoustic=True, acoustic_features)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "#Function for getting input vector and corresponding output      \n",
    "def parallel_task(d0, d1):\n",
    "    print(\"task...\")\n",
    "    # Each input diectory contains many file\n",
    "    # This fucntion will walk through all valid 'wav'files in this directory and get features like engergy, frequency...\n",
    "    def parseInput(dir):\n",
    "        dicts = {} \n",
    "        for f in os.listdir(dir):\n",
    "            if not f.startswith(\".\") and os.path.splitext(f)[1] == \".wav\":\n",
    "                dicts[os.path.splitext(f)[0]] = audio2Features(dir + \"/\" + f)\n",
    "\n",
    "\n",
    "        return dicts\n",
    "    audio2Features\n",
    "    # Each output file contains label of many diffrent 'wav' file.\n",
    "    # This function will parse content of text file using 'regrex'. Then turn it into label\n",
    "    def parseOutput(file):\n",
    "        dict_namefile_output = {}\n",
    "        # Open file to get all contents excepts the first line.\n",
    "        f = open(file, 'r')\n",
    "        content = \"\"\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            index = index + 1\n",
    "            if index == 1:\n",
    "                continue\n",
    "            content  = content + line\n",
    "\n",
    "        # Find all matched patterns in the content\n",
    "        ps = re.findall(r'\\[.*?\\)\\n\\n', content, re.DOTALL)\n",
    "\n",
    "        # Parse each matched pattern into  'Output' object\n",
    "        try:\n",
    "            for p in ps:\n",
    "                ls = p.split(\"\\n\")\n",
    "                ls = list(filter(lambda x: len(x) > 0 ,ls))\n",
    "\n",
    "                # Split elements of the first line which looks like : \n",
    "                # [147.0300 - 151.7101]\tSes01F_impro02_M012\tneu\t[2.5000, 2.0000, 2.0000]\n",
    "                ele_line0 = re.search(r'(\\[.*?\\])(\\s)(.*?)(\\s)(.*?)(\\s)(\\[.*?\\])', ls[0]).groups()\n",
    "\n",
    "                # Split time components which looks like:\n",
    "                # [147.0300 - 151.7101]\n",
    "                time_dur = ele_line0[0]\n",
    "                ele_time_dur = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", time_dur)\n",
    "                ele_time_dur = [float(x) for x in ele_time_dur]\n",
    "\n",
    "                # Get code and category_origin which looks like:\n",
    "                # Code: Ses01F_impro02_M012\n",
    "                # Category_origin: neu\n",
    "                code = ele_line0[2]\n",
    "                category_origin = ele_line0[4]\n",
    "\n",
    "                # Split attribute components which looks like:\n",
    "                # [2.5000, 2.0000, 2.0000]\n",
    "                attribute = ele_line0[6]\n",
    "                ele_attribute = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", attribute)\n",
    "                ele_attribute = [float(x) for x in ele_attribute]\n",
    "\n",
    "                # Get categorial_evaluation:\n",
    "                lines_categorical = list(filter(lambda x : x[0] == 'C', ls))\n",
    "                rex = re.compile(r'C.*?:(\\s)(.*?)(\\s)\\(.*?\\)')\n",
    "\n",
    "                category_evaluation = []\n",
    "                for l in lines_categorical:\n",
    "                    elements = rex.search(l).groups()\n",
    "                    cat = elements[1]\n",
    "                    cat = cat.split(\";\")\n",
    "                    cat = map(lambda x: x.lstrip(), cat)\n",
    "                    cat = list(filter(lambda x: len(x)>0, cat))\n",
    "                    category_evaluation.extend(cat)\n",
    "\n",
    "\n",
    "                # Make list distinct\n",
    "                category_evaluation = list(set(category_evaluation))\n",
    "                \n",
    "                \n",
    "\n",
    "                # Make dict {name_file : parsed_output}\n",
    "                dict_namefile_output[code] = Output(ele_time_dur, code, category_origin, category_evaluation, ele_attribute)\n",
    "            return dict_namefile_output\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    ### Parse input and output files and get input and output as vector\n",
    "    dicts_in = parseInput(d0)\n",
    "    dicts_out = parseOutput(d1)\n",
    "    in_out = []\n",
    "    \n",
    "    keys = list(dicts_in.keys())\n",
    "    for key in keys:\n",
    "        if(dicts_out[key].category_origin != 'xxx'):\n",
    "            if (method == METHOD['LSTM']):\n",
    "                in_out.append((dicts_in[key].input2Vec(onlySpectrogram=True), dicts_out[key].output2Vec()))\n",
    "            else:\n",
    "                in_out.append((dicts_in[key].input2Vec(onlySpectrogram=False), dicts_out[key].output2Vec()))\n",
    "    return in_out\n",
    "    \n",
    "    \n",
    "def createInput_Output():\n",
    "    ### Get directories of input and output\n",
    "    DATA_DIR = \"../../auditary_emotion_recognition/IEMOCAP_full_release\"\n",
    "    NUM_SESSION = 5\n",
    "    input_output = []\n",
    "    for i in range (1, NUM_SESSION + 1):\n",
    "        name_session = \"Session\" + str(i)\n",
    "        root_dir_of_wav = DATA_DIR + \"/\" + name_session + \"/sentences\" + \"/wav\"\n",
    "        root_dir_of_labels = DATA_DIR + \"/\" + name_session + \"/dialog\" + \"/EmoEvaluation\"\n",
    "\n",
    "        for x in os.walk(root_dir_of_wav):\n",
    "            if(x[0] == root_dir_of_wav):\n",
    "                dirs_of_wav = x[1]\n",
    "                index = -1\n",
    "            else:\n",
    "                index = index + 1\n",
    "                input_output.append((x[0], root_dir_of_labels + \"/\" + dirs_of_wav[index] + \".txt\"))\n",
    "                \n",
    "    \n",
    "    ds = input_output\n",
    "    in_out = []\n",
    "    input = []\n",
    "    out = []\n",
    "    \n",
    "    # Multi processing\n",
    "    with Pool(processes=8) as pool:\n",
    "         in_out = pool.starmap(parallel_task, ds)\n",
    "   \n",
    "    r = []\n",
    "    for e in in_out:\n",
    "        r = r + e\n",
    "    \n",
    "    input = [x[0] for x in r]\n",
    "    out = [x[1] for x in r]\n",
    "    print(\"Finished creating input output into txt file\")\n",
    "    return (input, out)\n",
    " \n",
    "\n",
    "\n",
    "#If have not processed data yet then process, otherwise loading data from file.\n",
    "if isRawDataProcessed == False:\n",
    "\n",
    "    ##Get input, normalize input, get output\n",
    "    input, output = createInput_Output()\n",
    "    output = np.array(output)\n",
    "    \n",
    "    if(method == METHOD['audio_feature']):\n",
    "        input = np.array(input)\n",
    "        input = input / input.max(axis=0)\n",
    "        filehandlerInput = open('processed-data/input.obj', 'wb')\n",
    "        filehandlerOutput = open('processed-data/output.obj', 'wb')\n",
    "    elif(method == METHOD['LSTM']):\n",
    "        # After this operator, each sample will be a 2-D array, Each row includes magnitude energy values in range of frquencies\n",
    "        # Rows will have the same length in all samples.\n",
    "        # Each sample will have different number of rows beacause their difference of length in seconds \n",
    "        #input = [list(map(list, zip(*i))) for i in input]\n",
    "        filehandlerInput = open('processed-data/input.obj', 'wb')\n",
    "        filehandlerOutput = open('processed-data/output.obj', 'wb')\n",
    "\n",
    "        \n",
    "    pickle.dump(input, filehandlerInput)\n",
    "    pickle.dump(output, filehandlerOutput)\n",
    "    print(\"Finish write processed data (input, output) to file!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
