{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,0,0]\n",
    "b= [1,1,0]\n",
    "if(a ==b):\n",
    "    print (\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Reshape, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import timeit\n",
    "from sklearn.utils import class_weight\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "#Constant\n",
    "EMOTION_ANNOTATORS = {'anger': 0, 'happiness' : 1, 'sadness' : 2, 'neutral' : 3, 'frustration' : 4, 'excited': 5,\n",
    "           'fear' : 6,'surprise' : 7,'disgust' : 8, 'other' : 9}\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n",
    "METHOD = {'audio_feature':0, 'LSTM':1, 'DRCNN' : 2}\n",
    "\n",
    "#Method for classification\n",
    "method = METHOD['DRCNN']\n",
    "\n",
    "#If data is processed and saved into files, just reload, dont need to re-process\n",
    "isRawDataProcessed = True\n",
    "\n",
    "#Development mode. Only run with small data.\n",
    "dev = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename\n",
    "import cv2\n",
    "\n",
    "##Load the array of input files and output lables. \n",
    "path_processed_data = \"processed-data\"\n",
    "dirs_data = ['ang', 'hap', 'sad', 'neu', 'fru', 'exc', 'fea', 'sur']\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "for dir in dirs_data:\n",
    "    for f in os.listdir(path_processed_data + \"/\" + dir):\n",
    "                if not f.startswith(\".\") and os.path.splitext(f)[1] == \".png\":\n",
    "                    image_paths.append(path_processed_data + \"/\" + dir + \"/\" + f)\n",
    "                    labels.append(EMOTION[dir])\n",
    "\n",
    "\n",
    "print (\"Finish load image_paths and lables!!\")\n",
    "print (\"Size data: \", len(image_paths))\n",
    "\n",
    "\n",
    "\n",
    "#Shuffle data and split into train and test set\n",
    "c = list(zip(image_paths, labels))\n",
    "random.shuffle(c)\n",
    "image_paths, labels = zip(*c)\n",
    "\n",
    "num_sample_train_data = int(0.95 * len(image_paths))\n",
    "train_image_paths = image_paths[0:num_sample_train_data]\n",
    "train_labels = labels[0:num_sample_train_data]\n",
    "\n",
    "\n",
    "valid_test_image_paths = image_paths[num_sample_train_data:]\n",
    "valid_test_labels = labels[num_sample_train_data:]\n",
    "\n",
    "number_sample_valid_data = int(0.6 * len(valid_test_image_paths))\n",
    "valid_image_paths = valid_test_image_paths[0:number_sample_valid_data]\n",
    "valid_labels = valid_test_labels[0:number_sample_valid_data]\n",
    "\n",
    "test_image_paths = valid_test_image_paths[number_sample_valid_data:]\n",
    "test_labels = valid_test_labels[number_sample_valid_data:]\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 8\n",
    "batch_size = 512\n",
    "width_image = 256\n",
    "channels = 3 #RGB\n",
    "epoch = 20\n",
    "\n",
    "\n",
    "def generate_batch_data(data_in, data_out, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(data_in), batch_size):\n",
    "            # create Numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x, y = process_data(data_in[i:i+batch_size], data_out[i:i+batch_size])\n",
    "            yield (x, y)\n",
    "\n",
    "\n",
    "##Function to transform these above array into data used for training and testing\n",
    "def process_data(image_paths, labels):\n",
    "    input = []\n",
    "    output = []\n",
    "    for path,label in zip(image_paths, labels):\n",
    "        img = cv2.imread(path)\n",
    "        #img = cv2.resize(img, (256, 256))\n",
    "        input.append(img)\n",
    "        \n",
    "        one_hot_coding_output = np.zeros((1,num_class))[0]\n",
    "        one_hot_coding_output[label] = 1\n",
    "        output.append(one_hot_coding_output)\n",
    "    \n",
    "    input = np.array(input)\n",
    "    output = np.array(output)\n",
    "    return input, output\n",
    "\n",
    "\n",
    "if method == METHOD['DRCNN']: \n",
    "    \n",
    "       \n",
    "    model = Sequential()\n",
    "    \n",
    "    #C1,P1\n",
    "    model.add(Conv2D(4, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(width_image, width_image, channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    #C2,P2\n",
    "    model.add(Conv2D(8, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    #C3\n",
    "    model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    \n",
    "    #C4\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    \n",
    "    #C5, P5\n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #F6, F7, F8\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #valid_in, valid_out = generate_batch_data(valid_image_paths, valid_labels)\n",
    "    #test_in, test_out = generate_batch_data(test_image_paths, test_labels)\n",
    "    #print(\"Finished generating data for validation and test.\")\n",
    "    \n",
    "    model.fit_generator(generate_batch_data(train_image_paths, train_labels, batch_size),\n",
    "                    steps_per_epoch = int(len(train_image_paths) / batch_size), epochs=10, \n",
    "                    validation_data = generate_batch_data(valid_image_paths, valid_labels, batch_size), \n",
    "                    validation_steps = int(len(valid_labels)/batch_size))\n",
    "    \n",
    "#     trained_epoch = 0\n",
    "#     for e in range(0, epoch):\n",
    "#         print(\"Epoch:\", e)\n",
    "#         for i in range (1, len(train_image_paths), batch_size):\n",
    "           \n",
    "            \n",
    "#             input, output = generate_batch_data(train_image_paths[i:i+batch_size], train_labels[i:i+batch_size])\n",
    "\n",
    "#             model.train_on_batch(input, output)\n",
    "#             loss_train = model.test_on_batch(input, output)\n",
    "#           #  loss_valid = model.test_on_batch(valid_in, valid_out)\n",
    "#             print(\"loss in batch of training set:\", loss_train)\n",
    "#            # print(\"loss in validation sset:\", loss_valid)\n",
    "\n",
    "        \n",
    "    #Test set\n",
    "#     predictions = model.predict_on_batch(test_in)\n",
    "    \n",
    "#     true_predict = 0\n",
    "#     for predict, label in zip(predictions, test_out):\n",
    "#         if (predict == label):\n",
    "#             true_predict = true_predict +1\n",
    "    \n",
    "#     print(\"Accuracy in test set: \", true_predict / len(predictions))\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "  \n",
    "    #Your statements here\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print (\"Time for training and testing: \", stop - start, \"(s)\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
