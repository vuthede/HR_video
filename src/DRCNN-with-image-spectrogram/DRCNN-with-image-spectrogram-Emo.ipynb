{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Reshape, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import timeit\n",
    "from sklearn.utils import class_weight\n",
    "from keras import optimizers\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n",
    "\n",
    "\n",
    "METHOD = {'audio_feature':0, 'LSTM':1, 'DRCNN' : 2}\n",
    "\n",
    "#Method for classification\n",
    "method = METHOD['DRCNN']\n",
    "\n",
    "#If data is processed and saved into files, just reload, dont need to re-process\n",
    "isRawDataProcessed = True\n",
    "\n",
    "#Development mode. Only run with small data.\n",
    "dev = False\n",
    "\n",
    "\n",
    "LABLE = {'W':0, 'L':1, 'E':2, 'A':3, 'F':4, 'T':5, 'N': 6}\n",
    "LABLE = {'W':0, 'A':1, 'F':2, 'T':3, 'N': 4}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename\n",
    "import cv2\n",
    "\n",
    "##Load the array of input files and output lables. \n",
    "path_processed_data = \"processed-data-Emo\"\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for f in os.listdir(path_processed_data):\n",
    "    if not f.startswith(\".\") and os.path.splitext(f)[1] == \".png\":\n",
    "        \n",
    "        file_name = f.split(\".\")[0]\n",
    "        label_code = file_name[5]\n",
    "        if (label_code == 'L' or label_code == 'E'):\n",
    "            continue\n",
    "            \n",
    "        lable_int = LABLE[label_code]\n",
    "        labels.append(lable_int)\n",
    "\n",
    "        image_paths.append(path_processed_data  + \"/\" + f)\n",
    "        \n",
    "print(\"num data:\", len(image_paths))\n",
    "#Shuffle data and split into train and test set\n",
    "c = list(zip(image_paths, labels))\n",
    "random.shuffle(c)\n",
    "image_paths, labels = zip(*c)\n",
    "\n",
    "num_sample_train_data = int(0.6 * len(image_paths))\n",
    "train_image_paths = image_paths[0:num_sample_train_data]\n",
    "train_labels = labels[0:num_sample_train_data]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "valid_test_image_paths = image_paths[num_sample_train_data:]\n",
    "valid_test_labels = labels[num_sample_train_data:]\n",
    "number_sample_valid_data = int(1 * len(valid_test_image_paths))\n",
    "valid_image_paths = valid_test_image_paths[0:number_sample_valid_data]\n",
    "valid_labels = valid_test_labels[0:number_sample_valid_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 5\n",
    "batch_size = 20\n",
    "width_image = 256\n",
    "channels = 3 #RGB\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "def generate_batch_data(data_in, data_out, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(data_in), batch_size):\n",
    "            # create Numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x, y = process_data(data_in[i:i+batch_size], data_out[i:i+batch_size])\n",
    "            #Normalize data\n",
    "            x = x / 255.0\n",
    "            yield (x, y)\n",
    "\n",
    "\n",
    "##Function to transform these above array into data used for training and testing\n",
    "def process_data(image_paths, labels):\n",
    "    input = []\n",
    "    output = []\n",
    "    for path,label in zip(image_paths, labels):\n",
    "        img = cv2.imread(path)\n",
    "        #img = cv2.resize(img, (256, 256))\n",
    "        input.append(img)\n",
    "        \n",
    "        one_hot_coding_output = np.zeros((1,num_class), dtype=int)[0]\n",
    "        #print(\"this is label: \",label )\n",
    "        one_hot_coding_output[label] = 1\n",
    "        output.append(one_hot_coding_output)\n",
    "    \n",
    "    input = np.array(input)\n",
    "    output = np.array(output)\n",
    "    return input, output\n",
    "\n",
    "\n",
    "if method == METHOD['DRCNN']: \n",
    "    \n",
    "       \n",
    "    model = Sequential()\n",
    "    \n",
    "    #C1,P1\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(width_image, width_image, channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    #C2,P2\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    #C3\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    \n",
    "    #C4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    \n",
    "    #C5, P5\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #F6, F7, F8\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    sgd = optimizers.SGD(lr=0.001, decay=1e-05, momentum=0.9, nesterov=True)\n",
    "   \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    \n",
    "    model.fit_generator(generate_batch_data(train_image_paths, train_labels, batch_size),\n",
    "                    steps_per_epoch = int(len(train_image_paths) / batch_size), epochs=num_epochs, \n",
    "                    validation_data = generate_batch_data(valid_image_paths, valid_labels, batch_size), \n",
    "                    validation_steps = int(len(valid_labels)/batch_size), shuffle=True)\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "  \n",
    "    #Your statements here\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print (\"Time for training and testing: \", stop - start, \"(s)\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
