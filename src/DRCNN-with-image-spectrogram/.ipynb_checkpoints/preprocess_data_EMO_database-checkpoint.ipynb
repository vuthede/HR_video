{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "import audiosegment\n",
    "from multiprocessing import Pool\n",
    "modulePath = '../../lib/ChristiansPythonLibrary/src' \n",
    "import sys\n",
    "import numpy\n",
    "sys.path.append(modulePath)\n",
    "import generalUtility\n",
    "import dspUtil\n",
    "import matplotlibUtil\n",
    "import librosa\n",
    "import pickle\n",
    "import string\n",
    "from random import *\n",
    "import cv2\n",
    "min_char = 8\n",
    "max_char = 20\n",
    "allchar = string.ascii_letters + string.digits\n",
    "\n",
    "def generate_random_string():\n",
    "     return \"\".join(choice(allchar) for x in range(randint(min_char, max_char)))\n",
    "\n",
    "default_dpi = 500\n",
    "isAugmentData = False\n",
    "    \n",
    "#Augmentation factor\n",
    "number_augmentated_per_image = 25\n",
    "max_u_over_f = 3\n",
    "u_over_f_values = numpy.arange(0.2, max_u_over_f, max_u_over_f / 40)\n",
    "print(u_over_f_values)\n",
    "scale_array = [ 1/ (np.abs((1-x)) + 0.1)    for x in u_over_f_values]\n",
    "scale_array  = numpy.abs(scale_array)\n",
    "print(scale_array)\n",
    "\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_IMAGE_OUT = \"processed-data-Emo\"\n",
    "\n",
    "def spectrogramToImage(freqs, times, amplitudes, dpi):\n",
    "    fig, ax = plt.subplots(dpi = dpi)\n",
    "    ax.pcolormesh(times, freqs, amplitudes)\n",
    "    ax.axis('off')\n",
    "\n",
    "    fig.canvas.draw ()\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    img = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "    return img\n",
    "\n",
    "def parallel_task(file_in):\n",
    "    \n",
    "    seg = audiosegment.from_file(file_in)\n",
    "    freqs, times, amplitudes = seg.spectrogram(window_length_s=0.03, overlap=0.5)\n",
    "    amplitudes = 10 * np.log10(amplitudes + 1e-9)\n",
    "\n",
    "    img = spectrogramToImage(freqs, times, amplitudes, dpi=default_dpi)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    \n",
    "    raw_file_path = file_in.split(\"/\")[-1].split(\".\")[0]\n",
    "   \n",
    "    \n",
    "    cv2.imwrite(FOLDER_IMAGE_OUT + \"/\" + raw_file_path + \".png\", img)\n",
    "        \n",
    "    if (isAugmentData == True):\n",
    "        print(\"Augmenting data....\")\n",
    "        for x in scale_array:\n",
    "        # plt.savefig(folder + \"/\" + generate_random_string() + file_out, transparent=True, dpi= int(default_dpi * x))\n",
    "            img = spectrogramToImage(freqs, times, amplitudes, dpi= int(default_dpi * x))\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            cv2.imwrite(FOLDER_IMAGE_OUT + \"/\" + raw_file_path + \".png\" ,img)\n",
    "\n",
    "def createInputOutput():\n",
    "    DATA_DIR = \"../../auditary_emotion_recognition/EMO-DATA\"\n",
    "    FOLDER_AUDIO = \"wav\"\n",
    "    files = []\n",
    "    \n",
    "    \n",
    "    for f in os.listdir(DATA_DIR + \"/\" + FOLDER_AUDIO):\n",
    "                if not f.startswith(\".\") and os.path.splitext(f)[1] == \".wav\":\n",
    "                    files.append(DATA_DIR + \"/\" + FOLDER_AUDIO + \"/\" + f)\n",
    "    \n",
    "    # Multi processing\n",
    "    with Pool(processes=8) as pool:\n",
    "        pool.map(parallel_task, files)\n",
    "   \n",
    "    print(\"Finished create histogram into files\")\n",
    "    \n",
    "    \n",
    "createInputOutput()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
