{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9\n",
      " 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5 3.6 3.7\n",
      " 3.8 3.9]\n",
      "[ 1.11111111  1.25        1.42857143  1.66666667  2.          2.5\n",
      "  3.33333333  5.         10.          5.          3.33333333  2.5\n",
      "  2.          1.66666667  1.42857143  1.25        1.11111111  1.\n",
      "  0.90909091  0.83333333  0.76923077  0.71428571  0.66666667  0.625\n",
      "  0.58823529  0.55555556  0.52631579  0.5         0.47619048  0.45454545\n",
      "  0.43478261  0.41666667  0.4         0.38461538  0.37037037  0.35714286\n",
      "  0.34482759  0.33333333]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "import audiosegment\n",
    "from multiprocessing import Pool\n",
    "modulePath = '../../lib/ChristiansPythonLibrary/src' \n",
    "import sys\n",
    "import numpy\n",
    "sys.path.append(modulePath)\n",
    "import generalUtility\n",
    "import dspUtil\n",
    "import matplotlibUtil\n",
    "import librosa\n",
    "import pickle\n",
    "import string\n",
    "from random import *\n",
    "import cv2\n",
    "min_char = 8\n",
    "max_char = 20\n",
    "allchar = string.ascii_letters + string.digits\n",
    "\n",
    "def generate_random_string():\n",
    "     return \"\".join(choice(allchar) for x in range(randint(min_char, max_char)))\n",
    "\n",
    "\n",
    "\n",
    "#default dpi\n",
    "default_dpi = 500\n",
    "\n",
    "\n",
    "#Augmentation factor\n",
    "number_augmentated_per_image = 25\n",
    "max_u_over_f = 3\n",
    "u_over_f_values = numpy.arange(0.2, max_u_over_f, max_u_over_f / 40)\n",
    "print(u_over_f_values)\n",
    "\n",
    "scale_array = [ 1/ (np.abs((1-x)) + 0.1)    for x in u_over_f_values]\n",
    "scale_array  = numpy.abs(scale_array)\n",
    "print(scale_array)\n",
    "\n",
    "#Constant\n",
    "EMOTION_ANNOTATORS = {'anger': 0, 'happiness' : 1, 'sadness' : 2, 'neutral' : 3, 'frustration' : 4, 'excited': 5,\n",
    "           'fear' : 6,'surprise' : 7,'disgust' : 8, 'other' : 9}\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n",
    "\n",
    "#Development mode. Only run with small data.\n",
    "dev = False\n",
    "\n",
    "#augment data bool\n",
    "isAugmentData = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-642f9bdc378f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m \u001b[0mcreateInput_Output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-642f9bdc378f>\u001b[0m in \u001b[0;36mcreateInput_Output\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mroot_dir_of_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_session\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/dialog\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/EmoEvaluation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir_of_wav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mroot_dir_of_wav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mdirs_of_wav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#Define class\n",
    "class Input:\n",
    "    ##spectral, prosody, erergy are dict type\n",
    "    def __init__(self, spectral, prosody, energy, spectrogram):\n",
    "        self.spectral = spectral\n",
    "        self.prosody = prosody\n",
    "        self.energy = energy\n",
    "        self.spectrogram = spectrogram\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"spectral  features: \", spectral)\n",
    "        print(\"prosody features: \", prosody)\n",
    "        print(\"energy: \", energy)\n",
    "        print(\"spectrogram: \", spectrogram)\n",
    "        \n",
    "    def input2Vec(self, onlySpectrogram):\n",
    "        if (onlySpectrogram ==  False):\n",
    "            features = []\n",
    "            s = list(self.spectral.values())\n",
    "            p = list(self.prosody.values())\n",
    "            e = list(self.energy.values())\n",
    "            [features.extend(x) for x in [s, p, e]]\n",
    "            return features\n",
    "        else :\n",
    "            return self.spectrogram\n",
    "    \n",
    "class Output:\n",
    "    def __init__(self, duration, code, category_origin, category_evaluation, attribute):\n",
    "        self.duration = duration\n",
    "        self.code = code\n",
    "        self.category_origin = category_origin\n",
    "        self.category_evaluation = category_evaluation\n",
    "        self.attribute = attribute\n",
    "        \n",
    "     \n",
    "    def print(self):\n",
    "        print(\"duration: \", self.duration)\n",
    "        print(\"code: \", self.code)\n",
    "        print(\"category_origin: \", self.category_origin)\n",
    "        print(\"category_evaluation: \", self.category_evaluation)\n",
    "        print(\"attribute: \", self.attribute)\n",
    "        \n",
    "    def output2Vec(self):\n",
    "        emotion = EMOTION[self.category_origin]\n",
    "        return emotion\n",
    "  \n",
    "\n",
    "\n",
    "def spectrogramToImage(freqs, times, amplitudes, dpi):\n",
    "    fig, ax = plt.subplots(dpi = dpi)\n",
    "    ax.pcolormesh(times, freqs, amplitudes)\n",
    "    ax.axis('off')\n",
    "\n",
    "    fig.canvas.draw ()\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    img = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "    return img\n",
    "\n",
    "def parallel_task(d0, d1):\n",
    "    print(\"task...\")\n",
    "    \n",
    "    \n",
    "    def create_histrogram(file_in, file_out, folder):\n",
    "        seg = audiosegment.from_file(file_in)\n",
    "        freqs, times, amplitudes = seg.spectrogram(window_length_s=0.03, overlap=0.5)\n",
    "        amplitudes = 10 * np.log10(amplitudes + 1e-9)\n",
    "        \n",
    "        img = spectrogramToImage(freqs, times, amplitudes, dpi=default_dpi)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        #print(\"hahah:\", folder + \"/\" + file_out + \".png\")\n",
    "        cv2.imwrite(folder + \"/\" + file_out + \".png\", img)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "        #plt.savefig(folder + \"/\" + file_out, transparent=True, dpi= default_dpi)\n",
    "        \n",
    "        if (isAugmentData == True) :\n",
    "            print(\"Augmenting data....\")\n",
    "            for x in scale_array:\n",
    "               # plt.savefig(folder + \"/\" + generate_random_string() + file_out, transparent=True, dpi= int(default_dpi * x))\n",
    "                img = spectrogramToImage(freqs, times, amplitudes, dpi= int(default_dpi * x))\n",
    "                img = cv2.resize(img, (256, 256))\n",
    "                cv2.imwrite(folder + \"/\" + generate_random_string() + file_out +\".png\", img)\n",
    "        \n",
    "    # Each input diectory contains many file\n",
    "    # This fucntion will walk through all valid 'wav'files in this directory and return the definite path of each file\n",
    "    def parseInput(dir):\n",
    "        dicts = {} \n",
    "        for f in os.listdir(dir):\n",
    "            if not f.startswith(\".\") and os.path.splitext(f)[1] == \".wav\":\n",
    "                dicts[os.path.splitext(f)[0]] = dir + \"/\" + f\n",
    "\n",
    "\n",
    "        return dicts\n",
    "    \n",
    "   # Get label of file\n",
    "    def parseOutput(file):\n",
    "        dict_namefile_output = {}\n",
    "        # Open file to get all contents excepts the first line.\n",
    "        f = open(file, 'r')\n",
    "        content = \"\"\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            index = index + 1\n",
    "            if index == 1:\n",
    "                continue\n",
    "            content  = content + line\n",
    "\n",
    "        # Find all matched patterns in the content\n",
    "        ps = re.findall(r'\\[.*?\\)\\n\\n', content, re.DOTALL)\n",
    "\n",
    "        # Parse each matched pattern into  'Output' object\n",
    "        try:\n",
    "            for p in ps:\n",
    "                ls = p.split(\"\\n\")\n",
    "                ls = list(filter(lambda x: len(x) > 0 ,ls))\n",
    "\n",
    "                # Split elements of the first line which looks like : \n",
    "                # [147.0300 - 151.7101]\tSes01F_impro02_M012\tneu\t[2.5000, 2.0000, 2.0000]\n",
    "                ele_line0 = re.search(r'(\\[.*?\\])(\\s)(.*?)(\\s)(.*?)(\\s)(\\[.*?\\])', ls[0]).groups()\n",
    "\n",
    "                # Split time components which looks like:\n",
    "                # [147.0300 - 151.7101]\n",
    "                time_dur = ele_line0[0]\n",
    "                ele_time_dur = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", time_dur)\n",
    "                ele_time_dur = [float(x) for x in ele_time_dur]\n",
    "\n",
    "                # Get code and category_origin which looks like:\n",
    "                # Code: Ses01F_impro02_M012\n",
    "                # Category_origin: neu\n",
    "                code = ele_line0[2]\n",
    "                category_origin = ele_line0[4]\n",
    "\n",
    "                # Split attribute components which looks like:\n",
    "                # [2.5000, 2.0000, 2.0000]\n",
    "                attribute = ele_line0[6]\n",
    "                ele_attribute = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", attribute)\n",
    "                ele_attribute = [float(x) for x in ele_attribute]\n",
    "\n",
    "                # Get categorial_evaluation:\n",
    "                lines_categorical = list(filter(lambda x : x[0] == 'C', ls))\n",
    "                rex = re.compile(r'C.*?:(\\s)(.*?)(\\s)\\(.*?\\)')\n",
    "\n",
    "                category_evaluation = []\n",
    "                for l in lines_categorical:\n",
    "                    elements = rex.search(l).groups()\n",
    "                    cat = elements[1]\n",
    "                    cat = cat.split(\";\")\n",
    "                    cat = map(lambda x: x.lstrip(), cat)\n",
    "                    cat = list(filter(lambda x: len(x)>0, cat))\n",
    "                    category_evaluation.extend(cat)\n",
    "\n",
    "\n",
    "                # Make list distinct\n",
    "                category_evaluation = list(set(category_evaluation))\n",
    "                \n",
    "                \n",
    "\n",
    "                # Make dict {name_file : parsed_output}\n",
    "                dict_namefile_output[code] = Output(ele_time_dur, code, category_origin, category_evaluation, ele_attribute)\n",
    "            return dict_namefile_output\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    ### Parse input and output files and get input and output as vector\n",
    "    dicts_in = parseInput(d0)\n",
    "    dicts_out = parseOutput(d1)\n",
    "    in_out = []\n",
    "    \n",
    "    keys = list(dicts_in.keys())\n",
    "    for key in keys:\n",
    "        if(dicts_out[key].category_origin != 'xxx' and dicts_out[key].category_origin != 'dis' and dicts_out[key].category_origin != 'oth'):\n",
    "            create_histrogram(dicts_in[key], key, \"processed-data/\" + dicts_out[key].category_origin)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "def createInput_Output():\n",
    "    ### Get directories of input and output\n",
    "    DATA_DIR = \"../../IEMOCAP_full_release\"\n",
    "    NUM_SESSION = 5\n",
    "    input_output = []\n",
    "    for i in range (1, NUM_SESSION + 1):\n",
    "        name_session = \"Session\" + str(i)\n",
    "        root_dir_of_wav = DATA_DIR + \"/\" + name_session + \"/sentences\" + \"/wav\"\n",
    "        root_dir_of_labels = DATA_DIR + \"/\" + name_session + \"/dialog\" + \"/EmoEvaluation\"\n",
    "\n",
    "        for x in os.walk(root_dir_of_wav):\n",
    "            if(x[0] == root_dir_of_wav):\n",
    "                dirs_of_wav = x[1]\n",
    "                index = -1\n",
    "            else:\n",
    "                index = index + 1\n",
    "                input_output.append((x[0], root_dir_of_labels + \"/\" + dirs_of_wav[index] + \".txt\"))\n",
    "                \n",
    "    \n",
    "    ds = input_output\n",
    "    in_out = []\n",
    "    input = []\n",
    "    out = []\n",
    "    \n",
    "    # Multi processing\n",
    "    with Pool(processes=8) as pool:\n",
    "        pool.starmap(parallel_task, ds)\n",
    "   \n",
    "    print(\"Finished create histogram into files\")\n",
    "\n",
    "\n",
    "createInput_Output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
