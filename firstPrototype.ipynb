{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'r' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c4d1bac643b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateInput_Output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c4d1bac643b6>\u001b[0m in \u001b[0;36mcreateInput_Output\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'r' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "import audiosegment\n",
    "from multiprocessing import Pool\n",
    "modulePath = 'ChristiansPythonLibrary/src' \n",
    "import sys\n",
    "import numpy\n",
    "sys.path.append(modulePath)\n",
    "import generalUtility\n",
    "import dspUtil\n",
    "import matplotlibUtil\n",
    "\n",
    "\n",
    "\n",
    "#Constant\n",
    "EMOTION_ANNOTATORS = {'anger': 0, 'happiness' : 1, 'sadness' : 2, 'neutral' : 3, 'frustration' : 4, 'excited': 5,\n",
    "           'fear' : 6,'surprise' : 7,'disgust' : 8, 'other' : 9}\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n",
    "\n",
    "\n",
    "#Define class\n",
    "class Input:\n",
    "    ##spectral, prosody, erergy are dict type\n",
    "    def __init__(self, spectral, prosody, energy):\n",
    "        self.spectral = spectral\n",
    "        self.prosody = prosody\n",
    "        self.energy = energy\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"spectral  features: \", spectral)\n",
    "        print(\"prosody features: \", prosody)\n",
    "        print(\"energy: \", energy)\n",
    "        \n",
    "    def input2Vec(self):\n",
    "        features = []\n",
    "        s = list(self.spectral.values())\n",
    "        p = list(self.prosody.values())\n",
    "        e = list(self.energy.values())\n",
    "        [features.extend(x) for x in [s, p, e]]\n",
    "        return features\n",
    "\n",
    "class Output:\n",
    "    def __init__(self, duration, code, category_origin, category_evaluation, attribute):\n",
    "        self.duration = duration\n",
    "        self.code = code\n",
    "        self.category_origin = category_origin\n",
    "        self.category_evaluation = category_evaluation\n",
    "        self.attribute = attribute\n",
    "        \n",
    "     \n",
    "    def print(self):\n",
    "        print(\"duration: \", self.duration)\n",
    "        print(\"code: \", self.code)\n",
    "        print(\"category_origin: \", self.category_origin)\n",
    "        print(\"category_evaluation: \", self.category_evaluation)\n",
    "        print(\"attribute: \", self.attribute)\n",
    "        \n",
    "    def output2Vec(self):\n",
    "        emotion = EMOTION[self.category_origin]\n",
    "        return emotion\n",
    "    \n",
    "    \n",
    "    \n",
    "#Functions for get features from audio file\n",
    "def amp2Db(samples):\n",
    "    dbs = []\n",
    "    for  x in samples:\n",
    "        if x < 0:\n",
    "            v = - dspUtil.rmsToDb(np.abs(x))\n",
    "        elif x == 0:\n",
    "            v = 0\n",
    "        else :\n",
    "            v = dspUtil.rmsToDb(np.abs(x))\n",
    "        dbs.append(v)\n",
    "    return dbs\n",
    "\n",
    "def getF0Features(file):\n",
    "    features = {}\n",
    "    sound = audiosegment.from_file(file)\n",
    "    voiced = sound.filter_silence(duration_s=0.2)\n",
    "    frame_rate = sound.frame_rate\n",
    "    frames = sound.dice(0.032)\n",
    "\n",
    "    f0s = []\n",
    "    for f in frames:\n",
    "        f0 = dspUtil.calculateF0once(amp2Db(f.get_array_of_samples()), frame_rate)\n",
    "        if(f0 != 0):\n",
    "            f0s.append(f0)\n",
    "    \n",
    "    features['f0_min'] = np.min(f0s)\n",
    "    features['f0_max'] = np.max(f0s)\n",
    "    features['f0_range'] = np.max(f0s) - np.min(f0s)\n",
    "    features['f0_mean'] = np.mean(f0s)\n",
    "    features['f0_median'] = np.median(f0s)\n",
    "    features['f0_25th'] = np.percentile(f0s, 25)\n",
    "    features['f0_75th'] = np.percentile(f0s, 75)\n",
    "    features['f0_std'] = np.std(f0s)\n",
    "    \n",
    "  \n",
    "    return features\n",
    "\n",
    "def getEnergyFeatures(file):\n",
    "    features = {}\n",
    "    sound = audiosegment.from_file(file)\n",
    "    voiced = sound.filter_silence(duration_s=0.2)\n",
    "    samples = voiced.get_array_of_samples()\n",
    "    frame_rate = sound.frame_rate\n",
    "    frames = sound.dice(0.032)\n",
    "    \n",
    "    e = []\n",
    "    for f in frames:\n",
    "        e.append(np.abs(f.max_dBFS))\n",
    "    \n",
    "    \n",
    "    features['energy_min'] = np.min(e)\n",
    "    features['energy_max'] = np.max(e)\n",
    "    features['energy_range'] = np.max(e) - np.min(e)\n",
    "    features['energy_mean'] = np.mean(e)\n",
    "    features['energy_median'] = np.median(e)\n",
    "    features['energy_25th'] = np.percentile(e, 25)\n",
    "    features['energy_75th'] = np.percentile(e, 75)\n",
    "    features['energy_std'] = np.std(e)   \n",
    "\n",
    "    return features\n",
    "    \n",
    "def audio2Features(file):\n",
    "    spectral = {}\n",
    "    prosody = {}\n",
    "    energy = {}\n",
    "    try:\n",
    "        prosody = getF0Features(file)\n",
    "        energy = getEnergyFeatures(file)\n",
    "        #To be continued....\n",
    "    \n",
    "        return Input(spectral, prosody, energy)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "#Function for getting input vector and corresponding output      \n",
    "def parallel_task(d0, d1):\n",
    "    # Each input diectory contains many file\n",
    "    # This fucntion will walk through all valid 'wav'files in this directory and get features like engergy, frequency...\n",
    "    def parseInput(dir):\n",
    "        dicts = {} \n",
    "        for f in os.listdir(dir):\n",
    "            if not f.startswith(\".\") and os.path.splitext(f)[1] == \".wav\":\n",
    "                dicts[os.path.splitext(f)[0]] = audio2Features(dir + \"/\" + f)\n",
    "\n",
    "\n",
    "        return dicts\n",
    "    \n",
    "    # Each output file contains label of many diffrent 'wav' file.\n",
    "    # This function will parse content of text file using 'regrex'. Then turn it into label\n",
    "    def parseOutput(file):\n",
    "        dict_namefile_output = {}\n",
    "        # Open file to get all contents excepts the first line.\n",
    "        f = open(file, 'r')\n",
    "        content = \"\"\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            index = index + 1\n",
    "            if index == 1:\n",
    "                continue\n",
    "            content  = content + line\n",
    "\n",
    "        # Find all matched patterns in the content\n",
    "        ps = re.findall(r'\\[.*?\\)\\n\\n', content, re.DOTALL)\n",
    "\n",
    "        # Parse each matched pattern into  'Output' object\n",
    "        try:\n",
    "            for p in ps:\n",
    "                ls = p.split(\"\\n\")\n",
    "                ls = list(filter(lambda x: len(x) > 0 ,ls))\n",
    "\n",
    "                # Split elements of the first line which looks like : \n",
    "                # [147.0300 - 151.7101]\tSes01F_impro02_M012\tneu\t[2.5000, 2.0000, 2.0000]\n",
    "                ele_line0 = re.search(r'(\\[.*?\\])(\\s)(.*?)(\\s)(.*?)(\\s)(\\[.*?\\])', ls[0]).groups()\n",
    "\n",
    "                # Split time components which looks like:\n",
    "                # [147.0300 - 151.7101]\n",
    "                time_dur = ele_line0[0]\n",
    "                ele_time_dur = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", time_dur)\n",
    "                ele_time_dur = [float(x) for x in ele_time_dur]\n",
    "\n",
    "                # Get code and category_origin which looks like:\n",
    "                # Code: Ses01F_impro02_M012\n",
    "                # Category_origin: neu\n",
    "                code = ele_line0[2]\n",
    "                category_origin = ele_line0[4]\n",
    "\n",
    "                # Split attribute components which looks like:\n",
    "                # [2.5000, 2.0000, 2.0000]\n",
    "                attribute = ele_line0[6]\n",
    "                ele_attribute = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", attribute)\n",
    "                ele_attribute = [float(x) for x in ele_attribute]\n",
    "\n",
    "                # Get categorial_evaluation:\n",
    "                lines_categorical = list(filter(lambda x : x[0] == 'C', ls))\n",
    "                rex = re.compile(r'C.*?:(\\s)(.*?)(\\s)\\(.*?\\)')\n",
    "\n",
    "                category_evaluation = []\n",
    "                for l in lines_categorical:\n",
    "                    elements = rex.search(l).groups()\n",
    "                    cat = elements[1]\n",
    "                    cat = cat.split(\";\")\n",
    "                    cat = map(lambda x: x.lstrip(), cat)\n",
    "                    cat = list(filter(lambda x: len(x)>0, cat))\n",
    "                    category_evaluation.extend(cat)\n",
    "\n",
    "\n",
    "                # Make list distinct\n",
    "                category_evaluation = list(set(category_evaluation))\n",
    "\n",
    "                # Make dict {name_file : parsed_output}\n",
    "                dict_namefile_output[code] = Output(ele_time_dur, code, category_origin, category_evaluation, ele_attribute)\n",
    "            return dict_namefile_output\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    ### Parse input and output files and get input and output as vector\n",
    "    dicts_in = parseInput(d0)\n",
    "    dicts_out = parseOutput(d1)\n",
    "    in_out = []\n",
    "    \n",
    "    keys = list(dicts_in.keys())\n",
    "    for key in keys:\n",
    "        if(dicts_out[key].category_origin != 'xxx'):\n",
    "            in_out.append((dicts_in[key].input2Vec(), dicts_out[key].output2Vec()))\n",
    "    return in_out\n",
    "    \n",
    "    \n",
    "def createInput_Output():\n",
    "    ### Get directories of input and output\n",
    "    DATA_DIR = \"IEMOCAP_full_release\"\n",
    "    NUM_SESSION = 5\n",
    "    input_output = []\n",
    "    for i in range (1, NUM_SESSION + 1):\n",
    "        name_session = \"Session\" + str(i)\n",
    "        root_dir_of_wav = DATA_DIR + \"/\" + name_session + \"/sentences\" + \"/wav\"\n",
    "        root_dir_of_labels = DATA_DIR + \"/\" + name_session + \"/dialog\" + \"/EmoEvaluation\"\n",
    "\n",
    "        for x in os.walk(root_dir_of_wav):\n",
    "            if(x[0] == root_dir_of_wav):\n",
    "                dirs_of_wav = x[1]\n",
    "                index = -1\n",
    "            else:\n",
    "                index = index + 1\n",
    "                input_output.append((x[0], root_dir_of_labels + \"/\" + dirs_of_wav[index] + \".txt\"))\n",
    "                \n",
    "    \n",
    "    ds = input_output\n",
    "    in_out = []\n",
    "    input = []\n",
    "    out = []\n",
    "    \n",
    "    # Multi processing\n",
    "    with Pool(processes=8) as pool:\n",
    "         in_out = pool.starmap(parallel_task, ds)\n",
    "   \n",
    "    r = []\n",
    "    for e in in_out:\n",
    "        r = r + e\n",
    "    \n",
    "    input = [x[0] for x in r]\n",
    "    out = [x[1] for x in r]\n",
    "            \n",
    "    return (input, out)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "##Get input, normalize input, get output\n",
    "input, output = createInput_Output()\n",
    "input = np.array(input)\n",
    "input = input / input.max(axis=0)\n",
    "output = np.array(output)\n",
    "\n",
    "np.savetxt('input.txt', input, fmt='%f')\n",
    "np.savetxt('output.txt', output, fmt='%d')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of training set:  0.04487179487179487\n",
      "Score of validation set:  0.06896551724137931\n",
      "Score of training set:  0.0\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.0\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.001282051282051282\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.001282051282051282\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.0\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.0\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.0012804097311139564\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.0\n",
      "Score of validation set:  0.0\n",
      "Score of training set:  0.0\n",
      "Score of validation set:  0.0\n",
      "Average accuracy training set, std: 0.0048716307167011395   0.013345699219885505\n",
      "Average accuracy validation set, std: 0.006896551724137931   0.02068965517241379\n",
      "dict_keys(['beta_1', 'tol', 'solver', 'random_state', 'nesterovs_momentum', 'beta_2', 'early_stopping', 'learning_rate_init', 'warm_start', 'alpha', 'batch_size', 'validation_fraction', 'epsilon', 'shuffle', 'momentum', 'learning_rate', 'activation', 'verbose', 'max_iter', 'power_t', 'hidden_layer_sizes'])\n",
      "predicts:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "prob:  [1.36095115e-01 7.61648402e-02 1.32606196e-01 3.41447317e-01\n",
      " 2.12288883e-01 8.19692728e-02 5.68860433e-03 1.14564520e-02\n",
      " 1.16879622e-03 1.17610659e-03 3.55825432e-06]\n",
      "SCore for test set:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sknn.mlp import Classifier, Layer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def training(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    kf = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "    i_fold = 0\n",
    "    accuracy_train_results = []\n",
    "    accuracy_valid_results = []\n",
    "\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        i_fold = i_fold + 1\n",
    "        \n",
    "        x_train_sub, x_valid_sub = X_train[train_index], X_train[valid_index]\n",
    "        y_train_sub, y_valid_sub = y_train[train_index], y_train[valid_index]\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20,), random_state=1)\n",
    "        clf.fit(x_train_sub, y_train_sub)\n",
    "        \n",
    "        score = clf.score(x_train_sub, y_train_sub)\n",
    "        score1 = clf.score(x_valid_sub, y_valid_sub)\n",
    "        accuracy_train_results.append(score)\n",
    "        accuracy_valid_results.append(score1)\n",
    "        \n",
    "        print(\"Score of training set: \", score)\n",
    "        print(\"Score of validation set: \", score1)\n",
    "     \n",
    "       \n",
    "    \n",
    "    avg_accuracy_train_result = np.sum(accuracy_train_results) / len(accuracy_train_results)\n",
    "    avg_accuracy_valid_result = np.sum(accuracy_valid_results) / len(accuracy_valid_results)\n",
    "    print(\"Average accuracy training set, std:\", avg_accuracy_train_result, \" \",\\\n",
    "          np.std(accuracy_train_results))\n",
    "    print(\"Average accuracy validation set, std:\", avg_accuracy_valid_result,\" \", \\\n",
    "          np.std(accuracy_valid_results))     \n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "   \n",
    "\n",
    "    predicts = clf.predict(X_test)\n",
    "    pro = clf.predict_proba(X_test)\n",
    "    print(\"predicts: \", predicts)\n",
    "    print(\"prob: \", pro[0])\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    print(\"SCore for test set: \", score_test)\n",
    "    print (\"Confusion matrix:..................... \")\n",
    "    matrix = confusion_matrix(y_test, predicts)\n",
    "    matrix_ratio = matrix/matrix.sum(1, keepdims=True)\n",
    "    print(matrix)\n",
    "    print(\"##########################\")\n",
    "    print(matrix_ratio)\n",
    " \n",
    "input = np.loadtxt('input.txt', dtype=float)\n",
    "output = np.loadtxt('output.txt', dtype=int)\n",
    "training(input, output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2122 2.    ]\n",
      " [3.     4.    ]]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# a = np.array([[1.2122,2],[3,4]])\n",
    "# np.savetxt('test1.txt', a, fmt='%f')\n",
    "# b = np.loadtxt('test1.txt', dtype=float)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
